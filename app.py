from flask import Flask, request, jsonify, Response, render_template, session
from flask_cors import CORS
from langchain_ollama import OllamaLLM
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
import json
import requests
import uuid
from datetime import datetime, timedelta

app = Flask(__name__)
app.secret_key = 'your-secret-key-change-this-in-production'
CORS(app)

# Ollama LLM ì´ˆê¸°í™”
llm = OllamaLLM(
    model="gemma3:4b",
    base_url="http://localhost:11434",
    temperature=0.7
)

# ì‚¬ìš©ìë³„ ë©”ëª¨ë¦¬ ì €ì¥ì†Œ
user_memories = {}
user_conversations = {}

def get_user_id():
    """ì‚¬ìš©ì ID ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
    if 'user_id' not in session:
        session['user_id'] = str(uuid.uuid4())
        print(f"ìƒˆë¡œìš´ ì‚¬ìš©ì ì„¸ì…˜ ìƒì„±: {session['user_id'][:8]}...")
    return session['user_id']

def get_user_memory(user_id):
    """ì‚¬ìš©ìë³„ ë©”ëª¨ë¦¬ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
    try:
        if user_id not in user_memories:
            print(f"ì‚¬ìš©ì {user_id[:8]}...ì˜ ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ ìƒì„±")
            user_memories[user_id] = ConversationBufferMemory(return_messages=True)
            user_conversations[user_id] = ConversationChain(
                llm=llm,
                memory=user_memories[user_id],
                verbose=True
            )
        
        return user_memories[user_id], user_conversations[user_id]
    
    except Exception as e:
        print(f"ë©”ëª¨ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ({user_id[:8]}...): {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê°•ì œë¡œ ìƒˆ ë©”ëª¨ë¦¬ ìƒì„±
        user_memories[user_id] = ConversationBufferMemory(return_messages=True)
        user_conversations[user_id] = ConversationChain(
            llm=llm,
            memory=user_memories[user_id],
            verbose=True
        )
        return user_memories[user_id], user_conversations[user_id]

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    user_id = get_user_id()
    return render_template('index.html')

@app.route('/user_info')
def user_info():
    """ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ"""
    user_id = get_user_id()
    memory_count = 0
    
    if user_id in user_memories:
        try:
            memory_count = len(user_memories[user_id].chat_memory.messages)
        except:
            memory_count = 0
    
    return jsonify({
        "user_id": user_id,
        "memory_count": memory_count,
        "total_users": len(user_memories)
    })

@app.route('/test', methods=['GET'])
def test_connection():
    """ì—°ê²° í…ŒìŠ¤íŠ¸"""
    user_id = get_user_id()
    try:
        response = llm.invoke("ì•ˆë…•í•˜ì„¸ìš”!")
        return jsonify({
            "status": "success",
            "response": response,
            "message": f"Ollama ì—°ê²° ì„±ê³µ! (ì‚¬ìš©ì: {user_id[:8]}...)",
            "user_id": user_id
        })
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": f"ì—°ê²° ì‹¤íŒ¨: {str(e)}",
            "user_id": user_id
        }), 500

@app.route('/prompt_engineering', methods=['POST'])
def prompt_engineering():
    """í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ - ì‚¬ìš©ìë³„ ë©”ëª¨ë¦¬ ì§€ì›"""
    user_id = get_user_id()
    
    try:
        data = request.json
        prompt_template = data.get('prompt', '')
        user_text = data.get('text', '')
        use_memory = data.get('use_memory', False)
        
        print(f"í”„ë¡¬í”„íŠ¸ ì‹¤í–‰: ì‚¬ìš©ì {user_id[:8]}..., ë©”ëª¨ë¦¬ ì‚¬ìš©: {use_memory}")
        
        if use_memory:
            # ì‚¬ìš©ìë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©
            try:
                user_memory, user_conversation = get_user_memory(user_id)
                
                if "{text}" in prompt_template:
                    final_prompt = prompt_template.replace("{text}", user_text)
                else:
                    final_prompt = f"{prompt_template}\n\n{user_text}"
                
                def generate_with_memory():
                    try:
                        print(f"ë©”ëª¨ë¦¬ ëª¨ë“œ ì‹¤í–‰ ì¤‘: {user_id[:8]}...")
                        response = user_conversation.predict(input=final_prompt)
                        
                        # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°
                        words = response.split()
                        for word in words:
                            yield f"data: {json.dumps({'token': word + ' '})}\n\n"
                        
                        yield f"data: {json.dumps({'done': True})}\n\n"
                        print(f"ë©”ëª¨ë¦¬ ëª¨ë“œ ì™„ë£Œ: {user_id[:8]}...")
                        
                    except Exception as e:
                        error_msg = f"ë©”ëª¨ë¦¬ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
                        print(error_msg)
                        yield f"data: {json.dumps({'error': error_msg})}\n\n"
                
                return Response(generate_with_memory(), 
                              mimetype='text/event-stream',
                              headers={'Cache-Control': 'no-cache'})
            
            except Exception as e:
                error_msg = f"ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}"
                print(error_msg)
                return jsonify({"error": error_msg, "status": "error"}), 500
        
        else:
            # ë©”ëª¨ë¦¬ ì—†ëŠ” ì§ì ‘ ìŠ¤íŠ¸ë¦¬ë°
            final_prompt = prompt_template.replace("{text}", user_text)
            
            def generate_direct():
                try:
                    print(f"ì§ì ‘ ëª¨ë“œ ì‹¤í–‰ ì¤‘: {user_id[:8]}...")
                    response = requests.post(
                        "http://localhost:11434/api/generate",
                        json={
                            "model": "gemma3:4b",
                            "prompt": final_prompt,
                            "stream": True
                        },
                        stream=True
                    )
                    
                    for line in response.iter_lines():
                        if line:
                            try:
                                chunk = json.loads(line.decode('utf-8'))
                                if 'response' in chunk:
                                    yield f"data: {json.dumps({'token': chunk['response']})}\n\n"
                                if chunk.get('done', False):
                                    yield f"data: {json.dumps({'done': True})}\n\n"
                                    break
                            except json.JSONDecodeError:
                                continue
                    
                    print(f"ì§ì ‘ ëª¨ë“œ ì™„ë£Œ: {user_id[:8]}...")
                    
                except Exception as e:
                    error_msg = f"ì§ì ‘ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
                    print(error_msg)
                    yield f"data: {json.dumps({'error': error_msg})}\n\n"
            
            return Response(generate_direct(), 
                          mimetype='text/event-stream',
                          headers={'Cache-Control': 'no-cache'})
        
    except Exception as e:
        error_msg = f"ì „ì²´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
        print(error_msg)
        return jsonify({
            "error": error_msg,
            "status": "error",
            "user_id": user_id
        }), 500

@app.route('/clear_prompt_memory', methods=['POST'])
def clear_prompt_memory():
    """ì‚¬ìš©ìë³„ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”"""
    user_id = get_user_id()
    
    try:
        # ê¸°ì¡´ ë©”ëª¨ë¦¬ ì™„ì „ ì‚­ì œ
        if user_id in user_memories:
            del user_memories[user_id]
            print(f"ê¸°ì¡´ ë©”ëª¨ë¦¬ ì‚­ì œ: {user_id[:8]}...")
        
        if user_id in user_conversations:
            del user_conversations[user_id]
            print(f"ê¸°ì¡´ ëŒ€í™” ì²´ì¸ ì‚­ì œ: {user_id[:8]}...")
        
        # ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ ìƒì„±
        user_memories[user_id] = ConversationBufferMemory(return_messages=True)
        user_conversations[user_id] = ConversationChain(
            llm=llm,
            memory=user_memories[user_id],
            verbose=True
        )
        
        print(f"ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ ìƒì„± ì™„ë£Œ: {user_id[:8]}...")
        
        return jsonify({
            "status": "success",
            "message": f"ì‚¬ìš©ì {user_id[:8]}...ì˜ ë©”ëª¨ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "user_id": user_id
        })
        
    except Exception as e:
        error_msg = f"ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}"
        print(error_msg)
        return jsonify({
            "error": error_msg,
            "status": "error",
            "user_id": user_id
        }), 500

if __name__ == '__main__':
    print("ğŸš€ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ Flask ì„œë²„ ì‹œì‘")
    print("ğŸ“¡ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5000 ìœ¼ë¡œ ì ‘ê·¼í•˜ì„¸ìš”")
    print("ğŸ‘¥ ì‚¬ìš©ìë³„ ë…ë¦½ì ì¸ ë©”ëª¨ë¦¬ ì§€ì›")
    print("ğŸ” ë””ë²„ê¹… ë¡œê·¸ í™œì„±í™”")
    app.run(debug=True, host='0.0.0.0', port=5000)
